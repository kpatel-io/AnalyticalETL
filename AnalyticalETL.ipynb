{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f409a7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import json\n",
    "import logging\n",
    "import yaml\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as func\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import year, month, dayofmonth,to_timestamp,to_date,split,substring,col,when\n",
    "from pyspark.sql.types import StructType,StructField,DateType,TimestampType,StringType,IntegerType,DecimalType\n",
    "from pyspark.sql.functions import udf, lit,split,concat,ceil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f61957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a spark session\n",
    "spark = SparkSession.builder.enableHiveSupport().appName(\"Analytical_ETL_spark\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43abd6ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-5-1c945f076be1>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-1c945f076be1>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    df = spark.read.parquet(\"C:/Users/KEVAL/Desktop/AnalyticalETL/trade/partition=2021-07-29\"\")\u001b[0m\n\u001b[1;37m                                                                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "# Loading the current date (7/29/2020) to a dataframe (df)\n",
    "df = spark.read.parquet(\"C:/Users/KEVAL/Desktop/AnalyticalETL/trade/partition=2021-07-29\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc473b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"tmp_trade_moving_avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99309cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the moving average for last 30 minutes\n",
    "mov_avg_df = spark.sql(\"\"\"select symbol, exchange, trade_dt,event_tm, event_seq_nb, trade_pr,\n",
    "                        AVG(trade_pr) OVER(PARTITION BY (symbol) ORDER BY CAST(event_tm AS timestamp) \n",
    "                        RANGE BETWEEN INTERVAL 30 MINUTES PRECEDING AND CURRENT ROW) as mov_avg_pr\n",
    "                        from tmp_trade_moving_avg\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a68bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DROP HIVE TABLE IF EXISTS\n",
    "spark.sql(\"DROP TABLE IF EXISTS temp_trade_moving_avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7301d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the data frame as table in hive\n",
    "mov_avg_df.write.saveAsTable(\"temp_trade_moving_avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae68c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_avg_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0990765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the previous date (7/28/2020) to a dataframe (df)\n",
    "df = spark.read.parquet(\"C:/Users/KEVAL/Desktop/AnalyticalETL/trade/partition=2021-07-28\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66768bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"temp_last_trade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37b0c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the moving average for last 30 minutes\n",
    "last_pr_df = spark.sql(\"\"\"select symbol, trade_dt,exchange, event_tm, event_seq_nb, trade_pr,\n",
    "                        AVG(trade_pr) OVER(PARTITION BY (symbol) ORDER BY CAST(event_tm AS timestamp) \n",
    "                        RANGE BETWEEN INTERVAL 30 MINUTES PRECEDING AND CURRENT ROW) as last_pr\n",
    "                        from temp_last_trade\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfbb2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP HIVE TABLE IF EXISTS\n",
    "spark.sql(\"DROP TABLE IF EXISTS temp_last_trade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe142f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data frame as table in hive\n",
    "last_pr_df.write.saveAsTable(\"temp_last_trade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950cdaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_pr_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c41aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Quotes Data for 2021-04-18\n",
    "quotes = spark.read.parquet(\"hdfs://localhost:8020/stock/partition=Q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d6133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes.createOrReplaceTempView(\"quotes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123e6d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Union Quotes and Trades into Union View\n",
    "quote_union = spark.sql(\"\"\"\n",
    "SELECT trade_dt,rec_type,symbol,event_tm,event_seq_nb,exchange,bid_pr,bid_size,ask_pr,\n",
    "ask_size,null as trade_pr,null as mov_avg_pr FROM quotes\n",
    "UNION\n",
    "SELECT trade_dt,\"T\" as rec_type,symbol,event_tm,event_seq_nb,exchange,null as bid_pr,null as bid_size,null as ask_pr,\n",
    "null as ask_size,trade_pr,mov_avg_pr FROM temp_trade_moving_avg\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b416373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_union.createOrReplaceTempView(\"quote_union\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3db55f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Populate the last not null trade price and moving average price from trade records\n",
    "quote_union_update = spark.sql(\"\"\"\n",
    "select *,\n",
    "last_value(trade_pr,true) OVER(PARTITION BY (symbol) \n",
    "ORDER BY CAST(event_tm AS timestamp) DESC) as last_trade_pr,\n",
    "last_value(mov_avg_pr,true) OVER(PARTITION BY (symbol) \n",
    "ORDER BY CAST(event_tm AS timestamp) DESC) as last_mov_avg_pr\n",
    "from quote_union\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcb3fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_union_update.createOrReplaceTempView(\"quote_union_update\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0721c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter Quote records\n",
    "quote_update = spark.sql(\"\"\"\n",
    "select trade_dt, symbol, event_tm, event_seq_nb, exchange,\n",
    "bid_pr, bid_size, ask_pr, ask_size, last_trade_pr, last_mov_avg_pr\n",
    "from quote_union_update\n",
    "where rec_type = 'Q'\n",
    "\"\"\")\n",
    "quote_update.createOrReplaceTempView(\"quote_update\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1118fdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join with table temp_last_trade to retrieve prior day close day\n",
    "quote_final = spark.sql(\"\"\"\n",
    "select trade_dt, A.symbol, event_tm, event_seq_nb, exchange,\n",
    "bid_pr, bid_size, ask_pr, ask_size, last_trade_pr, last_mov_avg_pr,\n",
    "bid_pr - close_pr as bid_pr_mv, ask_pr - close_pr as ask_pr_mv\n",
    "from quote_update A LEFT OUTER JOIN (select distinct symbol,last_pr as close_pr from temp_last_trade) B\n",
    "on A.symbol = B.symbol\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4480d633",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a366e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_date = \"2021-07-29\"\n",
    "quote_final.write.mode(\"overwrite\").parquet(\"C:/Users/KEVAL/Desktop/AnalyticalETL/stock/quote-trade-analytical/date={}\".fo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
